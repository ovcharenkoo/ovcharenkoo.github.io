---
layout: single
permalink: /courses/
author_profile: true
---

<!-- <h3>Bio</h3> -->
<section class="home__custom">
    As a certified instructor at <a href="https://www.nvidia.com/en-us/training/">NVIDIA Deep Learning Institute</a> I teach the following courses
    <br>

    <!-- NLP -->
    <h2><a href="https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+C-FX-03+V3">Building Transformer-Based Natural Language Processing Applications</a></h2>
    Learn how to apply and fine-tune a Transformer-based Deep Learning model to Natural Language Processing (NLP) tasks. 
    In this course, you'll: 
    construct a Transformer neural network in PyTorch,
    build a named-entity recognition (NER) application with BERT,
    deploy the NER application with ONNX and TensorRT to a Triton inference server.
    Upon completion, you’ll be proficient in task-agnostic applications of Transformer-based models.

    <!-- RAD -->
    <h2><a href="https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+C-FX-09+V1">Rapid Application Development Using Large Language Models</a></h2>
    Recent advancements in both the techniques and accessibility of large language models (LLMs) have opened up unprecedented opportunities to help businesses streamline 
    their operations, decrease expenses, and increase productivity at scale. Additionally, enterprises can use LLM-powered apps to provide innovative and improved services 
    to clients or strengthen customer relationships. For example, enterprises could provide customer support via AI companions or use sentiment analysis apps to extract valuable customer insights. 
    In this course you will gain a strong understanding and practical knowledge of LLM application development by exploring the open-sourced ecosystem including pretrained LLMs, 
    enabling you to get started quickly in developing LLM-based applications.

    <!-- RAG -->
    <h2><a href="https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-15+V1">Building RAG Agents with LLMs</a></h2>
    The evolution and adoption of large language models (LLMs) have been nothing short of revolutionary, with retrieval-based systems at the 
    forefront of this technological leap. These models are not just tools for automation; they are partners in enhancing productivity, capable of holding informed conversations 
    by interacting with a vast array of tools and documents. This course is designed for those eager to explore the potential of these systems, focusing on practical deployment 
    and the efficient implementation required to manage the considerable demands of both users and deep learning models. As we delve into the intricacies of LLMs, participants 
    will gain insights into advanced orchestration techniques that include internal reasoning, dialog management, and effective tooling strategies.

    <!-- Efficient LLM customization -->
    <h2><a href="https://www.nvidia.com/en-sg/training/instructor-led-workshops/efficient-large-language-model-customization/">Efficient Large Language Model (LLM) Customization</a></h2>
    In this course, you'll go beyond prompt engineering LLMs and learn a variety of techniques to efficiently customize pretrained LLMs for your specific use cases—without engaging in the 
    computationally intensive and expensive process of pretraining your own model or fine-tuning a model's internal weights. 
    Using NVIDIA NeMo service, you’ll learn various parameter-efficient fine-tuning methods to customize LLM behavior for your organization.

    <!-- Numba -->
    <h2><a href="https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+C-AC-02+V1">Fundamentals of Accelerated Computing with CUDA Python</a></h2>
    This course explores how to use Numba—the just-in-time, type-specializing Python function compiler—to accelerate Python programs to run on massively parallel NVIDIA GPUs. 
    You’ll learn how to: · Use Numba to compile CUDA kernels from NumPy universal functions (ufuncs) 
    · Use Numba to create and launch custom CUDA kernels 
    · Apply key GPU memory management techniques 
    Upon completion, you’ll be able to use Numba to compile and launch CUDA kernels to accelerate your Python applications on NVIDIA GPUs.

    <!-- RAPIDS -->
    <h2><a href="https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+C-DS-02+V1">Fundamentals of Accelerated Data Science</a></h2>
    Whether you work at a software company that needs to improve customer retention, a financial services company that needs to mitigate risk, or a retail company 
    interested in predicting customer purchasing behavior, your organization is tasked with preparing, managing, and gleaning insights from large volumes of data 
    without wasting critical resources. Traditional CPU-driven data science workflows can be cumbersome, but with the power of GPUs, your teams can make sense of data 
    quickly to drive business decisions.

    <!-- Fundamentals of DL -->
    <h2><a href="https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+C-FX-01+V3">Fundamentals of Deep Learning</a></h2>
    Businesses worldwide are using artificial intelligence to solve their greatest challenges. 
    Healthcare professionals use AI to enable more accurate, faster diagnoses in patients. Retail businesses use it to offer personalized customer shopping experiences. 
    Automakers use it to make personal vehicles, shared mobility, and delivery services safer and more efficient. 
    Deep learning is a powerful AI approach that uses multi-layered artificial neural networks to deliver state-of-the-art accuracy in tasks such as object detection, speech recognition, and language translation. 
    Using deep learning, computers can learn and recognize patterns from data that are considered too complex or subtle for expert-written software.

</section>